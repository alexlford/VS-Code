{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39ba724",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue;border: 2px solid gray;\">\n",
    "    <h2 style =\"text-align:center; padding-top:5px;\"> CS 101 - Foundation of Data Science and Engineering  </h2><br>\n",
    "    <p style=\"text-align:center;padding:5px; fontt-size:14px\"><b> PSET-4 - Managing Data Excercise-2 (100 pts)<b></p> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c845d",
   "metadata": {},
   "source": [
    "### This is an individual assignment. No collaboration is allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabaa058",
   "metadata": {},
   "source": [
    "### Assignment Goal:\n",
    " \n",
    "**Part-1 : Explore Pandas, perform data cleaning using Pandas.**\n",
    "\n",
    "**Part-2 : Generate random sample data in SQL**\n",
    "\n",
    "**Part-3 : Practice writing SQL queries**\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad46be2",
   "metadata": {},
   "source": [
    "**Start by reviewing the provided file nj_teachers_salaries_pset4.csv. Examine the column names, data types of this data file. After reviewing this file please provide your solutions for the questions below.**\n",
    "\n",
    "**Note: The file has identical columns that you worked on PSET-3, however all the data are not identical**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d0f1b",
   "metadata": {},
   "source": [
    "**Resources:**<br>\n",
    "**https://pandas.pydata.org/docs/reference/frame.html**<br>\n",
    "**Module 4 & Module 5 Lectures**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9d649",
   "metadata": {},
   "source": [
    "**Please feel free to create new cells in your notebook for completing the assignment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5709bcb",
   "metadata": {},
   "source": [
    "# Part-1 (60 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe347e3",
   "metadata": {},
   "source": [
    "**In this part you will be working with Pandas to explore and clean data. For each of the questions, please make sure that you show your work on what was done in each step.**\n",
    "\n",
    "**For Example if you drop rows, be sure to show the how many rows were dropped at each step. You can use \n",
    "df.shape to show before and after count.**\n",
    "\n",
    "**For Questions 3-5 that involve modifying your values, you need to show us few rows where the modification was done. \n",
    "As an example you are looking at df['experience_total'] column and you discover that the column has values that are not numerical. You go ahead and set the values as np.NAN.  You should show that those values were indeed set  as nan. You can use print statements or simply create a new cell and show some example rows. Please display relevant rows and not the full dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a291e796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a8464d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector as sq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d3ca40",
   "metadata": {},
   "source": [
    "## Question-1 (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e434b31",
   "metadata": {},
   "source": [
    "### Create a dataframe called df using the provided csv file nj_teachers_salaries_pset4.csv. Use df.info() to get the information about the columns, non-null values, and data type inferred by Pandas for each column. \n",
    "\n",
    "**Pandas tries to infer the data type of each column. However if you have a numerical column, with an invalid value (such as a string), it will infer it as an object. String values are inferred as object data type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "327c0e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100005 entries, 0 to 100004\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   id                   99998 non-null   float64\n",
      " 1   last_name            100003 non-null  object \n",
      " 2   first_name           100003 non-null  object \n",
      " 3   county               100003 non-null  object \n",
      " 4   district             100003 non-null  object \n",
      " 5   school               100003 non-null  object \n",
      " 6   primary_job          100003 non-null  object \n",
      " 7   fte                  100003 non-null  object \n",
      " 8   salary               99983 non-null   object \n",
      " 9   certificate          100003 non-null  object \n",
      " 10  subcategory          100003 non-null  object \n",
      " 11  teaching_route       100003 non-null  object \n",
      " 12  highly_qualified     100003 non-null  object \n",
      " 13  experience_district  100003 non-null  object \n",
      " 14  experience_nj        100003 non-null  object \n",
      " 15  experience_total     99983 non-null   object \n",
      "dtypes: float64(1), object(15)\n",
      "memory usage: 12.2+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/m1yk_rm10nx5rd9pwp0n6qtc0000gn/T/ipykernel_44082/1607330085.py:1: DtypeWarning: Columns (7,8,13,14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"nj_teachers_salaries_pset4.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>county</th>\n",
       "      <th>district</th>\n",
       "      <th>school</th>\n",
       "      <th>primary_job</th>\n",
       "      <th>fte</th>\n",
       "      <th>salary</th>\n",
       "      <th>certificate</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>teaching_route</th>\n",
       "      <th>highly_qualified</th>\n",
       "      <th>experience_district</th>\n",
       "      <th>experience_nj</th>\n",
       "      <th>experience_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Heckman</td>\n",
       "      <td>William</td>\n",
       "      <td>Bergen</td>\n",
       "      <td>River Edge Boro</td>\n",
       "      <td>Cherry Hill School</td>\n",
       "      <td>Elementary School Teacher K-5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98774</td>\n",
       "      <td>Standard certificate</td>\n",
       "      <td>General ed</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>Not highly qualified</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Bird</td>\n",
       "      <td>Kelly</td>\n",
       "      <td>Bergen</td>\n",
       "      <td>Wood-ridge Boro</td>\n",
       "      <td>Catherine E. Doyle Elementary School</td>\n",
       "      <td>Art</td>\n",
       "      <td>1.0</td>\n",
       "      <td>118415</td>\n",
       "      <td>Standard certificate</td>\n",
       "      <td>General ed</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>Doesnt need to be highly qualified</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Aikens</td>\n",
       "      <td>Crystal A</td>\n",
       "      <td>Bergen</td>\n",
       "      <td>Emerson Boro</td>\n",
       "      <td>Patrick M Villano School</td>\n",
       "      <td>Kindergarten</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57919</td>\n",
       "      <td>Standard certificate</td>\n",
       "      <td>General ed</td>\n",
       "      <td>Alternate</td>\n",
       "      <td>Doesnt need to be highly qualified</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Leonard</td>\n",
       "      <td>Isaiah</td>\n",
       "      <td>Gloucester</td>\n",
       "      <td>Deptford Twp</td>\n",
       "      <td>Deptford Township High School</td>\n",
       "      <td>Elementary Kindergraten-8 Grade</td>\n",
       "      <td>0.8</td>\n",
       "      <td>107746</td>\n",
       "      <td>CEAS</td>\n",
       "      <td>Special ed</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>Doesn't need to be highly qualified</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Hinton</td>\n",
       "      <td>Dustin</td>\n",
       "      <td>Camden</td>\n",
       "      <td>Cherry Hill Twp</td>\n",
       "      <td>Cherry Hill High School West</td>\n",
       "      <td>English Non-elementary</td>\n",
       "      <td>0.8</td>\n",
       "      <td>54277</td>\n",
       "      <td>Standard certificate</td>\n",
       "      <td>General ed</td>\n",
       "      <td>Traditional</td>\n",
       "      <td>Doesn't need to be highly qualified</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id last_name first_name      county         district  \\\n",
       "0  1.0   Heckman    William      Bergen  River Edge Boro   \n",
       "1  2.0      Bird      Kelly      Bergen  Wood-ridge Boro   \n",
       "2  3.0    Aikens  Crystal A      Bergen     Emerson Boro   \n",
       "3  4.0   Leonard     Isaiah  Gloucester     Deptford Twp   \n",
       "4  5.0    Hinton     Dustin      Camden  Cherry Hill Twp   \n",
       "\n",
       "                                 school                      primary_job  fte  \\\n",
       "0                    Cherry Hill School    Elementary School Teacher K-5  1.0   \n",
       "1  Catherine E. Doyle Elementary School                              Art  1.0   \n",
       "2              Patrick M Villano School                     Kindergarten  1.0   \n",
       "3         Deptford Township High School  Elementary Kindergraten-8 Grade  0.8   \n",
       "4          Cherry Hill High School West           English Non-elementary  0.8   \n",
       "\n",
       "   salary           certificate subcategory teaching_route  \\\n",
       "0   98774  Standard certificate  General ed    Traditional   \n",
       "1  118415  Standard certificate  General ed    Traditional   \n",
       "2   57919  Standard certificate  General ed      Alternate   \n",
       "3  107746                  CEAS  Special ed    Traditional   \n",
       "4   54277  Standard certificate  General ed    Traditional   \n",
       "\n",
       "                      highly_qualified experience_district experience_nj  \\\n",
       "0                 Not highly qualified                 9.0           9.0   \n",
       "1   Doesnt need to be highly qualified                13.0          13.0   \n",
       "2   Doesnt need to be highly qualified                 7.0           7.0   \n",
       "3  Doesn't need to be highly qualified                26.0          26.0   \n",
       "4  Doesn't need to be highly qualified                 5.0           5.0   \n",
       "\n",
       "  experience_total  \n",
       "0                9  \n",
       "1               13  \n",
       "2                7  \n",
       "3               26  \n",
       "4                5  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"nj_teachers_salaries_pset4.csv\")\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee0fe64",
   "metadata": {},
   "source": [
    "## Question-2 (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2028011c",
   "metadata": {},
   "source": [
    "### Drop rows that have all values as NaN. (Recall from lecture that you have to set the parameter how='all') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0cf108bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34185d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Question-3 (20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d614e58",
   "metadata": {},
   "source": [
    "### Numerical Columns :\n",
    "\n",
    "### Identify numerical columns excluding id column, remove any invalid characters from numerical columns by first setting it to np.NAN , and finally drop rows containing NaN values. (5))\n",
    "\n",
    "### Set the correct data type for each of the numerical columns (i.e. int , float) (1)\n",
    "\n",
    "## Check the id column. Set the correct id number for rows that are NA/NaN. Set the correct dtype.(5)\n",
    "\n",
    "### At the end of this step your dataframe should not contain any invalid values for numerical values. Only invalid/missing values should have been dropped. (5)\n",
    "\n",
    "\n",
    "### Please be sure to show your work, meaning , show few example rows that were actually modified. (4)   \n",
    "\n",
    "### Note : do not reset the index of the dataframe at any point. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5171405b-8861-4e0e-a7d6-b8a6d6b362cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = num_cols = [\"fte\", \"salary\", \"experience_district\", \"experience_nj\", \"experience_total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8b389199-e49c-4bf1-8c04-7638cf18aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_num(col):\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "for col in num_cols:\n",
    "    clean_num(col)\n",
    "\n",
    "df.dropna(subset=num_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "032eab69-ce70-490b-9655-4d3b3f7100db",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_cols = [\"experience_district\", \"experience_nj\", \"experience_total\"]\n",
    "for col in int_cols:\n",
    "    df[col] = df[col].astype(str).str.strip()  # remove spaces\n",
    "\n",
    "# convert to numeric\n",
    "df[int_cols] = df[int_cols].apply(pd.to_numeric)\n",
    "\n",
    "# convert to integer\n",
    "df[int_cols] = df[int_cols].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "13a48ba9-1a68-4397-9003-9c5f20f1042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "float_cols = [\"fte\", \"salary\"]\n",
    "for col in float_cols:\n",
    "    df[col] = df[col].astype(str).str.strip()  # remove spaces\n",
    "\n",
    "# convert to numeric\n",
    "df[int_cols] = df[int_cols].apply(pd.to_numeric)\n",
    "\n",
    "# convert to float\n",
    "df[int_cols] = df[int_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "500d6894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/m1yk_rm10nx5rd9pwp0n6qtc0000gn/T/ipykernel_44082/1726291065.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['id'].fillna(method='ffill', inplace=True)\n",
      "/var/folders/14/m1yk_rm10nx5rd9pwp0n6qtc0000gn/T/ipykernel_44082/1726291065.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['id'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# drop rows with NaN values in numerical columns\n",
    "df.dropna(subset=num_cols, inplace=True)\n",
    "\n",
    "# id column \n",
    "df['id'].fillna(method='ffill', inplace=True)\n",
    "df['id'] = df['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32179431-d275-4c55-87fd-8c4617ab6a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified numerical column values:\n",
      "   fte    salary  experience_district  experience_nj  experience_total\n",
      "0  1.0   98774.0                  9.0            9.0               9.0\n",
      "1  1.0  118415.0                 13.0           13.0              13.0\n",
      "2  1.0   57919.0                  7.0            7.0               7.0\n",
      "3  0.8  107746.0                 26.0           26.0              26.0\n",
      "4  0.8   54277.0                  5.0            5.0               5.0\n",
      "5  0.5   82772.0                  1.0           20.0              20.0\n",
      "6  0.8   51379.0                 39.0           39.0              39.0\n",
      "7  1.0   96061.0                  1.0            1.0               1.0\n",
      "8  1.0  107300.0                 22.0            1.0              24.0\n",
      "9  0.8   87862.0                 15.0           15.0              15.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Modified numerical column values:\")\n",
    "print(df[num_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f624f3e6",
   "metadata": {},
   "source": [
    "## Question-4 (5 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db700d9",
   "metadata": {},
   "source": [
    "### String Columns:\n",
    "\n",
    "### Identify string/object columns. Remove any leading and trailing spaces. This can be applied to all string columns (3)\n",
    "### Show example rows/columns where leading and trailing spaces were removed.Hint : first_name,last_name have data values with leading and trailing spaces. Show at least 2 such examples where data values were modified for these columns. (2)\n",
    "\n",
    "### No rows should be dropped.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a36ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_cols = df.select_dtypes(include=['object']).columns\n",
    "df[string_cols] = df[string_cols].apply(lambda x: x.str.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c0e21809-3609-40a0-9178-481a5826024c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example rows where spaces were removed:\n",
      "  first_name last_name\n",
      "0    William   Heckman\n",
      "1      Kelly      Bird\n",
      "2  Crystal A    Aikens\n",
      "3     Isaiah   Leonard\n",
      "4     Dustin    Hinton\n",
      "5     Robert   Richard\n",
      "6       Chad    Duncan\n",
      "7     Dennis  Peterson\n",
      "8    Anthony     Logan\n",
      "9      Jerry     Riley\n"
     ]
    }
   ],
   "source": [
    "print(\"Example rows where spaces were removed:\")\n",
    "print(df[['first_name', 'last_name']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f832694",
   "metadata": {},
   "source": [
    "## Question-5 (20 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06952cce",
   "metadata": {},
   "source": [
    "### Additional Cleaning - String Column :\n",
    "\n",
    "### Perform additional cleaning on string columns. Remove any special/invalid characters from the string columns.\n",
    "\n",
    "### Example :\n",
    "### df['primary_job'] contains a value 'Family & Consumer Sciences â€“ Apparel, Textiles And Interiors'.\n",
    "\n",
    "### The special character should be removed to give the value 'Family & Consumer Sciences  Apparel, Textiles And Interiors' (2.5 pts)\n",
    "\n",
    "\n",
    "### Perform data cleaning on at least 3 string columns. You will have to identify data values in your string columns, and remove any special characters. (7.5) pts\n",
    "\n",
    "### You should try to avoid setting string columns to np.NAN , and dropping it. However, it is ok if you set some rows to np.NAN and drop it for which values are completely invalid. In the end you should have approximately the same number of rows that you had after finishing Question 3. \n",
    "\n",
    "### We are not looking for a perfect solution. The data may still consist of invalid values. We are more interested in seeing how you have applied your learning to this assignment. \n",
    "\n",
    "\n",
    "### In all cases please show your work, meaning show us few example rows/columns where the data values were actually modified. (10 pts)\n",
    "\n",
    "### Note : In general letters, numbers, punctuations , & , /, \\, () , - , :, s'_,.,?!&/-:#@   are considered valid. You can choose to include more characters.  However, for first name and last name, teaching_route, subcategory you will want to choose only specific characters to be considered valid. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5f8858c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/14/m1yk_rm10nx5rd9pwp0n6qtc0000gn/T/ipykernel_44082/2282228724.py:4: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df[string_cols] = df[string_cols].applymap(clean_text)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_text\u001b[39m(text):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^a-zA-Z0-9 &(),.:?!@#/-]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(text))\n\u001b[0;32m----> 4\u001b[0m df[string_cols] \u001b[38;5;241m=\u001b[39m df[string_cols]\u001b[38;5;241m.\u001b[39mapplymap(clean_text)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10522\u001b[0m, in \u001b[0;36mDataFrame.applymap\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10473\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  10474\u001b[0m \u001b[38;5;124;03mApply a function to a Dataframe elementwise.\u001b[39;00m\n\u001b[1;32m  10475\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10515\u001b[0m \u001b[38;5;124;03m1  5  5\u001b[39;00m\n\u001b[1;32m  10516\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  10517\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m  10518\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.applymap has been deprecated. Use DataFrame.map instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m  10519\u001b[0m     \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m  10520\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  10521\u001b[0m )\n\u001b[0;32m> 10522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmap(func, na_action\u001b[38;5;241m=\u001b[39mna_action, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10468\u001b[0m, in \u001b[0;36mDataFrame.map\u001b[0;34m(self, func, na_action, **kwargs)\u001b[0m\n\u001b[1;32m  10465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[1;32m  10466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m> 10468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(infer)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mapply()\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_generator()\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(v, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10466\u001b[0m, in \u001b[0;36mDataFrame.map.<locals>.infer\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m  10465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minfer\u001b[39m(x):\n\u001b[0;32m> 10466\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\u001b[38;5;241m.\u001b[39m_map_values(func, na_action\u001b[38;5;241m=\u001b[39mna_action)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m, in \u001b[0;36mclean_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclean_text\u001b[39m(text):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[^a-zA-Z0-9 &(),.:?!@#/-]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(text))\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub(r'[^a-zA-Z0-9 &(),.:?!@#/-]', '', str(text))\n",
    "\n",
    "df[string_cols] = df[string_cols].applymap(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee3ab4-4f36-42eb-a3d5-a440e28082cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c11dbc-3ef5-4cfe-959e-b4236d5a37e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c4c0a-e841-498e-9201-d648433c0885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e277b5b-f270-419c-b10c-b3fc92317c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c312c0e9-dc91-4da4-a1b1-ae34f803e34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f913d9a2-f03b-4a8f-a70a-b04edcc4321a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "908cf6bb",
   "metadata": {},
   "source": [
    "## Question-6 (1 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b70b1",
   "metadata": {},
   "source": [
    "### Drop any duplicate rows. Display df.info() to shows the data types, and Non-Null count. \n",
    "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bad33d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9562f-1eca-4f10-965b-abc051aa0777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca9b27-48f8-4410-a1b1-75cb24d0b50e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f6af6de",
   "metadata": {},
   "source": [
    "## Question -7 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7685921",
   "metadata": {},
   "source": [
    "### Save your cleaned dataframe as  cleaned_data.csv. Be sure to set the parameter index = False to avoid saving the index as an extra column\n",
    "\n",
    "ex:\n",
    "df.to_csv(\"cleaned_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c6c91e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"cleaned_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d3085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a05cbf6",
   "metadata": {},
   "source": [
    "## Question -8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1908b9",
   "metadata": {},
   "source": [
    "### Similar to PSET-3 \n",
    "\n",
    "### 8.1 Connect to your MySql database using your username and password. Name the cursor returned from the mysql connection object as mycursor. (1 pts)\n",
    "\n",
    "\n",
    "### 8.2 Use the same database as PSET-3 nj_state_teachers_salaries, or if you have deleted it create a database called nj_state_teachers_salaries\n",
    "\n",
    "\n",
    "### 8.3 Create a table called teachers_salaries_pset4 with all the columns in your cleaned_data.csv. For this part ,be sure to use appropriate data type for all the columns.  If you are facing difficulty creating a column with Float or bool or int , it is ok to store it as TEXT. (MAX 2 allowed for numerical columns being stored as TEXT) (3 pts)\n",
    "\n",
    "\n",
    "### 8.4 Using LOAD DATA statement (as discussed in Module 4 lectures) load the data from cleaned_data.csv to your table created in 8.3. Use of OPTIONALLY ENCLOSED BY  clause and TERMINATED by clause is recommended. (3 pts)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0aa0e7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = sq.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"idp/dt=[H,p]\",\n",
    "    allow_local_infile=True, \n",
    "    database=\"nj_state_teachers_salaries\"\n",
    ")\n",
    "mycursor = mydb.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e3123aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS teachers_salaries_pset4 (\n",
    "    id INT PRIMARY KEY,\n",
    "    last_name VARCHAR(255),\n",
    "    first_name VARCHAR(255),\n",
    "    county VARCHAR(255),\n",
    "    district VARCHAR(255),\n",
    "    school VARCHAR(255),\n",
    "    primary_job VARCHAR(255),\n",
    "    fte FLOAT,\n",
    "    salary FLOAT,\n",
    "    certificate VARCHAR(255),\n",
    "    subcategory VARCHAR(255),\n",
    "    teaching_route VARCHAR(255),\n",
    "    highly_qualified VARCHAR(255),\n",
    "    experience_district INT,\n",
    "    experience_nj INT,\n",
    "    experience_total INT\n",
    ");\n",
    "\"\"\"\n",
    "mycursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a9c02aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data_query = \"\"\"\n",
    "LOAD DATA LOCAL INFILE 'cleaned_data.csv'\n",
    "INTO TABLE teachers_salaries_pset4\n",
    "FIELDS TERMINATED BY ','\n",
    "OPTIONALLY ENCLOSED BY '\"'\n",
    "LINES TERMINATED BY '\\n'\n",
    "IGNORE 1 ROWS;\n",
    "\"\"\"\n",
    "mycursor.execute(load_data_query)\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "262fc1e9-46f9-46e4-a636-e9a726e1b0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in table: 99954\n"
     ]
    }
   ],
   "source": [
    "mycursor.execute(\"SELECT COUNT(*) FROM teachers_salaries_pset4\")\n",
    "print(f\"Number of rows in table: {mycursor.fetchone()[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7cb666",
   "metadata": {},
   "source": [
    "### Question 9 - For this question you are only required to run the cells. To get credit  your code from Question 8 must have been successfully run, and executed. No credit will be awarded if data was loaded using MySQL workbench. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81271dfc",
   "metadata": {},
   "source": [
    "## Question 9 (5 pts)\n",
    "\n",
    "Run the 2 cells below. The code checks if all the data rows and columns were stored in the database. \n",
    "\n",
    "The code below assumes that you named your cursor object as mycursor(As specified in Question-8). If you named it differently, you can rename mycursor to match the variable name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4c84b407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in teachers_salaries table : 99954\n"
     ]
    }
   ],
   "source": [
    "cmd = \"select count(*) from \\\n",
    "                 nj_state_teachers_salaries.teachers_salaries_pset4 \"\n",
    "mycursor.execute(cmd)\n",
    "count = mycursor.fetchone()[0]\n",
    "\n",
    "print(f\"Number of rows in teachers_salaries table : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a9f8d503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in teachers_salaries table : 16\n"
     ]
    }
   ],
   "source": [
    "cmd = \"\"\"SELECT COUNT(*) \\\n",
    "                FROM INFORMATION_SCHEMA.COLUMNS \\\n",
    "                WHERE table_schema = 'nj_state_teachers_salaries' \\\n",
    "                AND table_name = 'teachers_salaries_pset4'\"\"\"\n",
    "mycursor.execute(cmd)\n",
    "count = mycursor.fetchone()[0]\n",
    "print(f\"Number of columns in teachers_salaries table : {count}\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203aacd",
   "metadata": {},
   "source": [
    "# End of Part-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b47ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c82f9052",
   "metadata": {},
   "source": [
    "### For both Part-2 and Part-3 you will need to work on MySQL workbench. For both parts you must submit .sql files. More information below. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29229e41",
   "metadata": {},
   "source": [
    "# Part-2 (10 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5727a55",
   "metadata": {},
   "source": [
    "**For this part you will generate a random sample data from the table you created in Part-1 and save it as a csv file. Generating random samples have many use cases in the real world. For example, you are a developer who is working on a software application that requires access to a critical database. Instead you maybe given only a sample of data to work with to develop your application. Another use case is bootstrapping in statistics, or when you test your models with samples of data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6daab5",
   "metadata": {},
   "source": [
    "## Question 1 (8 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6381b9",
   "metadata": {},
   "source": [
    "### Use a SELECT statement to generate and output a random sample to : \n",
    "### Include all columns \n",
    "### Include field (column) headings \n",
    "### Randomly select 777 records with a seed value of 7 \n",
    "### Output results to a csv file named sample.csv \n",
    "### save your sql as  output.sql . You will submit this file as a part of this assignment. \n",
    "\n",
    "**You will find module 5 lecture on SQL Random Sample Generation useful**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dd4a04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee5c6647",
   "metadata": {},
   "source": [
    "## Question 2 (2 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09885ed7",
   "metadata": {},
   "source": [
    "### Create a dataframe using sample.csv generated from Question-1. Display the first 5 rows, and last 5 rows. Print the shape of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf04910",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f6892e-a68e-4044-a7c0-6540d176006c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53d13a27",
   "metadata": {},
   "source": [
    "# Part-3 (30 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bfaae8",
   "metadata": {},
   "source": [
    "**For this part you will work on sql queries. You will write your queries for the provided dataset teachersample.csv. We could have asked you to write the queries based on the existing table nj_state_teachers_salaries.teachers_salaries_pset4 , however everyone's data cleaning process will be different resulting in different dataset.** \n",
    "\n",
    "**All work need to be done in MySQL workbench**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867b4ea",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ced2812",
   "metadata": {},
   "source": [
    "### Create a table called salaries within the nj_state_teachers_salaries database. Load the data in to the table from the provided file teachersample.csv. The teachersample.csv does not contain the id column. Please modify your code to work with this csv file. \n",
    "\n",
    "### You don't need to submit the code for this. This table is intended only for queries in Question-2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4500f520",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbb786aa",
   "metadata": {},
   "source": [
    "## Question 2 (30 pts)\n",
    "## Each query is worth 3 pts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db6f76d",
   "metadata": {},
   "source": [
    "### Write the following queries in MySQL workbench, and name the file queries.sql.  The file you submit should have the exact name for you to get credit. We will run your query, so you don't need to capture the output. The file should include only the 10 queries. Be sure to test it before submission. \n",
    "\n",
    "**Example Query for your reference:**\n",
    "\n",
    "**select count(*) from nj_state_teachers_salaries.salaries;**\n",
    "\n",
    "#### Note : Please include the name of the database and the table in each query as shown in the above example. End each query with a semicolon as shown in example.Your file queries.sql should be able to execute any any machine that has the nj_state_teachers_salaries database and the salaries table.  We will deduct upto 10 pts if queries.sql does not execute. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f160c0f-0f6c-4901-b922-94c994454d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3848fb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1. Calculate the average salary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4e5c0a",
   "metadata": {},
   "source": [
    "### 2. Calculate the number of people whose salary is more than 150,000. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18956d6",
   "metadata": {},
   "source": [
    "### 3. Get the last name of the ones who make more than 150,000 but have less than 5 years of total experience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6896e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86469e13",
   "metadata": {},
   "source": [
    "### 4. Get the highest salary for Preschool, School Counselor, Principal (anyone with the word Principal in the title), School Psychologist, and Kindergarten. (These are individual queries.  You should have 5 separate queries.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bb4a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63d4758e",
   "metadata": {},
   "source": [
    "### 5. Get the last name, first name, and salary of the lowest earner who works in Atlantic City "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78a518",
   "metadata": {},
   "source": [
    "### 6. Get the total number of employees working in Passaic City with more than ten years of total experience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d94e14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588dbd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad18a901",
   "metadata": {},
   "source": [
    "## Submission on Gradescope\n",
    "\n",
    "**Gradescope canvas left menu -> Gradescop -> PSET 4: Managing Data Excercise 2**\n",
    "\n",
    "**Submission :**\n",
    "\n",
    "**Part -1  : This jupyter notebook, and a pdf of this notebook.** \n",
    "\n",
    "**Part -2 : output.sql and sample.csv**\n",
    "\n",
    "**Part -3 :  queries.sql containing all your queries.  This file should only include the sql queries. Please don't include the code that created the salaries table.** \n",
    "\n",
    "\n",
    "\n",
    "**To create a pdf of this notebook :  In your browser open print, and save as pdf. Name the pdf LastNameFirstName.pdf\n",
    "example: DoeJohn.pdf**\n",
    "\n",
    "**Name this jupyter notebook with the same format LastNameFirstName.ipynb**\n",
    "\n",
    "\n",
    "**Make sure that your notebook has been run before creating pdf. Any outputs from running the code needs to be clearly visible. We need all the files from Part-1, Part-2, and Part-3 to assign you grades.** \n",
    "\n",
    "\n",
    "**Drop all the files in gradescope under PSET 4: Managing Data Exercise 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950c84c-7936-44fe-b9e0-8161cbff16fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1d3c134-b90a-48e7-9601-f1b640f045c1",
   "metadata": {},
   "source": [
    "### Submission Note (Please read)\n",
    "\n",
    "**After submitting your files on Gradescope , You may an error that says**\n",
    "\n",
    "**\"The autograder failed to execute correctly. Contact your course staff for help in debugging this issue. Make sure to include a link to this page so that they can help you most effectively.\"**\n",
    "\n",
    "### You don't have to take any action , and you do not need to contact us. The error is beacuse of some internal setup on Gradescope. As long as you have followed the specs, and submitted all the required files, you are good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba8b5cb-2696-4206-ab78-5ba338871a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
