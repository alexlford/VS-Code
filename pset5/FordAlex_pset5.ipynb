{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdad8ff",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue;border: 2px solid gray;\">\n",
    "    <h2 style =\"text-align:center; padding-top:5px;\"> CS 101 - Foundation of Data Science and Engineering  </h2><br>\n",
    "    <p style=\"text-align:center;padding:5px; fontt-size:14px\"><b> PSET-5 - Exploratory Data Analysis (100 pts)<b></p> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca83fb",
   "metadata": {},
   "source": [
    "# This is an individual assignment. No collaboration is allowed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ec799",
   "metadata": {},
   "source": [
    "### Note: \n",
    "You are allowed to use all Python built-in functions and other Import features covered in class. Ensure your code is organized, well-commented, and follows the best practices we discussed. Remember, the key is not just to write a working program but to produce a solution that follows SPECS, is easy to debug, and is easy to maintain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41163e5e",
   "metadata": {},
   "source": [
    "### Assignment Question List:\n",
    " \n",
    "**Question 1 : Data Extraction and cleaning (1 pts)**\n",
    "\n",
    "**Question 2 : Column Cleaning Function (15 pts)**\n",
    "\n",
    "**Question 3 : Data Cleaning (9 pts)**\n",
    "\n",
    "**Question 4 : Data Aggregation (30 pts)**\n",
    "\n",
    "**Question 5 : Merging Data (10 pts)**\n",
    "\n",
    "**Question 6 : Filtering Data (30 pts)**\n",
    "\n",
    "**Coding Style : (5 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab336b0",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "**You are tasked with performing detailed exploratory data analysis on various system datasets: CPU, Disk, and Memory. Utilize Python functions to streamline data extraction, cleaning, and aggregation.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32b9bd",
   "metadata": {},
   "source": [
    "### Datasets:\n",
    "\n",
    "1. **CPU Dataset: `cpu.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Description', 'Status', 'Threads', 'CPU', 'Average CPU'\n",
    "   <br><br>\n",
    "2. **Disk Dataset: `disk.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Model', 'Read Byte Per Second', 'Write Byte Per Second', 'Delay', 'Total Byte Per Second'\n",
    "    <br><br>\n",
    "3. **Memory Dataset: `memory.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Hard Faults/sec', 'Commit KB', 'Working Set KB', 'Shareable KB', 'Private KB'\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89055f",
   "metadata": {},
   "source": [
    "# Your Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1d8f8",
   "metadata": {},
   "source": [
    "### 1. Data Extraction (1 pts):\n",
    "\n",
    "a. **Load `cpu.csv` into a Pandas DataFrame named `df_cpu`. Extract only these columns:** 'Image', 'PID', 'Description', 'Status', 'Threads', 'Average CPU'\n",
    "\n",
    "b. **Load `disk.csv` into a DataFrame named `df_disk`. Extract only these columns:** 'Image', 'PID', 'Total Byte Per Second'\n",
    "\n",
    "c. **Load `memory.csv` into a DataFrame named `df_memory`. Extract only these columns:** 'Image', 'PID', 'Working Set KB'\n",
    "\n",
    "d. **For each of the above data frame show the shape, and info(example : df_cpu.info())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2abb771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load datasets\n",
    "df_cpu = pd.read_csv(\"cpu.csv\")\n",
    "df_disk = pd.read_csv(\"disk.csv\")\n",
    "df_memory = pd.read_csv(\"memory.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0b822932-5984-456c-a944-5ab01338cb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Image        306 non-null    object \n",
      " 1   PID          306 non-null    object \n",
      " 2   Description  290 non-null    object \n",
      " 3   Status       306 non-null    object \n",
      " 4   Threads      306 non-null    object \n",
      " 5   CPU          306 non-null    int64  \n",
      " 6   Average CPU  306 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 16.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((306, 7), None)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cpu.shape, df_cpu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fa75e715-b3d1-4fdf-b8f9-d67d2eae2c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Image                  14 non-null     object\n",
      " 1   PID                    14 non-null     int64 \n",
      " 2   Model                  14 non-null     object\n",
      " 3   Read Byte Per Second   14 non-null     object\n",
      " 4   Write Byte Per Second  14 non-null     object\n",
      " 5   Delay                  14 non-null     int64 \n",
      " 6   Total Byte Per Second  14 non-null     object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 916.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((14, 7), None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disk.shape, df_disk.info(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "020c0dee-133a-470e-a204-2ad5dd5b467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Image            306 non-null    object\n",
      " 1   PID              306 non-null    int64 \n",
      " 2   Hard Faults/sec  306 non-null    int64 \n",
      " 3   Commit KB        306 non-null    object\n",
      " 4   Working Set KB   306 non-null    object\n",
      " 5   Shareable KB     306 non-null    object\n",
      " 6   Private KB       306 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 16.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((306, 7), None)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_memory.shape, df_memory.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dec275",
   "metadata": {},
   "source": [
    "### 2. Column Cleaning Function (15 pts):\n",
    "\n",
    "a. **Write a Python function, `CleanColumnHeading(dfx)`, to clean the column headers of any Pandas dataframe. The function should be dynamic enough to be able to process any datasets. The function should:**\n",
    "\n",
    "   i. Convert all column names to lowercase.\n",
    "   \n",
    "   ii. Replace spaces in column names with underscores `_`.\n",
    "\n",
    "   iii. Apply the `CleanColumnHeading` function to `df_cpu`, `df_disk`, and `df_memory`.\n",
    "\n",
    "   iv. Show examples of the changes.  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "Function header:\n",
    "```python\n",
    "def CleanColumnHeading(dfx):\n",
    "    # Your code to convert all column names to lowercase\n",
    "    # Your code to change all spaces in column names to underscores _\n",
    "    return dfx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8f3b5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanColumnHeading(dfx):\n",
    "    dfx.columns = dfx.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    return dfx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d0392dea-7102-4a1e-baf7-afa87d823ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpu = CleanColumnHeading(df_cpu)\n",
    "df_disk = CleanColumnHeading(df_disk)\n",
    "df_memory = CleanColumnHeading(df_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8db8ed38-5f06-4364-a146-825c01ea270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   image        306 non-null    object \n",
      " 1   pid          306 non-null    object \n",
      " 2   description  290 non-null    object \n",
      " 3   status       306 non-null    object \n",
      " 4   threads      306 non-null    object \n",
      " 5   cpu          306 non-null    int64  \n",
      " 6   average_cpu  306 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 16.9+ KB\n",
      "            image    pid  description     status threads  cpu  average_cpu\n",
      "0   Secure System    140          NaN  Suspended       -    0          0.0\n",
      "1  SearchHost.exe   9272   SearchHost  Suspended      68    0          0.0\n",
      "2     LockApp.exe  12784  LockApp.exe  Suspended      16    0          0.0\n"
     ]
    }
   ],
   "source": [
    "df_cpu.info()\n",
    "print(df_cpu.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ddd238f0-8152-4731-a8ba-503f5c59b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   image                  14 non-null     object\n",
      " 1   pid                    14 non-null     int64 \n",
      " 2   model                  14 non-null     object\n",
      " 3   read_byte_per_second   14 non-null     object\n",
      " 4   write_byte_per_second  14 non-null     object\n",
      " 5   delay                  14 non-null     int64 \n",
      " 6   total_byte_per_second  14 non-null     object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 916.0+ bytes\n",
      "        image    pid model read_byte_per_second write_byte_per_second  delay  \\\n",
      "0  chrome.exe   5448     x                    0                 6,278      0   \n",
      "1  chrome.exe  13324    x3                    0                 4,940      0   \n",
      "2   EXCEL.EXE  12132    x1               71,807                     0      0   \n",
      "\n",
      "  total_byte_per_second  \n",
      "0                 6,278  \n",
      "1                 4,940  \n",
      "2                71,807  \n"
     ]
    }
   ],
   "source": [
    "df_disk.info()\n",
    "print(df_disk.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8abdc19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   image            306 non-null    object\n",
      " 1   pid              306 non-null    int64 \n",
      " 2   hard_faults/sec  306 non-null    int64 \n",
      " 3   commit_kb        306 non-null    object\n",
      " 4   working_set_kb   306 non-null    object\n",
      " 5   shareable_kb     306 non-null    object\n",
      " 6   private_kb       306 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 16.9+ KB\n",
      "                           image    pid  hard_faults/sec commit_kb  \\\n",
      "0  AcrobatNotificationClient.exe  18096                0    40,272   \n",
      "1      Adobe Crash Processor.exe   7856                0     4,768   \n",
      "2      Adobe Desktop Service.exe   6640                0    85,284   \n",
      "\n",
      "  working_set_kb shareable_kb private_kb  \n",
      "0          3,632        3,392        240  \n",
      "1         15,252       13,704      1,548  \n",
      "2         85,504       75,696      9,808  \n"
     ]
    }
   ],
   "source": [
    "df_memory.info()\n",
    "print(df_memory.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e86fa-c8c8-4e50-9f75-517491d29e68",
   "metadata": {},
   "source": [
    "### 3. Data cleaning (9 pts)\n",
    "**Examine the columns 'threads', 'total_byte_per_second', 'working_set_kb' from the dataframes df_cpu, df_disk, and df_memory. We are going to work with these columns Question 4-6. Ensure that they have the correct data type, fix the values if required so. If there are invalid values drop them. At the end of this step you should not have any invalid values, and the correct data type set for the 3 columns. You are not required to do data cleaning on other columns. If you choose to do so, please ensure that no rows are dropped while cleaning these columns** \n",
    "\n",
    "**Hint: values such as 71,807 are not invalid. They are simply string representation of the number 71807. Fix it so they are stored as 71807, and the column datatype should either be a float or int.** \n",
    "\n",
    "\n",
    "**For each of the columns modified , show example rows of what was modified. Also call the info() method on each of the dataframes.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "61a1a8e5-9532-4624-a143-2ff579b99909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_column(dfx, column_name):\n",
    "    dfx[column_name] = pd.to_numeric(dfx[column_name].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "    #drop rows with NaN\n",
    "    dfx.dropna(subset=[column_name], inplace=True)\n",
    "    #convert to integer type if possible\n",
    "    if dfx[column_name].dtype == 'float64' and (dfx[column_name] % 1 == 0).all():\n",
    "        dfx[column_name] = dfx[column_name].astype(int)\n",
    "\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "50664004-97f4-4f5e-b47b-b4c1d75cc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpu_beforecleaned = df_cpu.copy()\n",
    "df_disk_beforecleaned = df_disk.copy()\n",
    "df_memory_beforecleaned = df_memory.copy()\n",
    "df_cpu = clean_numeric_column(df_cpu, 'threads')\n",
    "df_disk = clean_numeric_column(df_disk, 'total_byte_per_second')\n",
    "df_memory = clean_numeric_column(df_memory, 'working_set_kb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8418df3f-bd4c-4179-ae8b-3b705164902a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify modified\n",
    "df_cpu_modified = df_cpu_beforecleaned[\n",
    "    df_cpu_beforecleaned['threads'].astype(str).str.contains(',', na=False)]\n",
    "df_disk_modified = df_disk_beforecleaned[\n",
    "    df_disk_beforecleaned['total_byte_per_second'].astype(str).str.contains(',', na=False)]\n",
    "df_memory_modified = df_memory_beforecleaned[\n",
    "    df_memory_beforecleaned['working_set_kb'].astype(str).str.contains(',', na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6e988c47-5362-4b97-8ae3-eb77936239c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 304 entries, 1 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   image        304 non-null    object \n",
      " 1   pid          304 non-null    object \n",
      " 2   description  289 non-null    object \n",
      " 3   status       304 non-null    object \n",
      " 4   threads      304 non-null    int64  \n",
      " 5   cpu          304 non-null    int64  \n",
      " 6   average_cpu  304 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 19.0+ KB\n",
      "Examples of modified values in df_cpu in 'threads' column:\n",
      "No modifications were needed in 'threads' column.\n"
     ]
    }
   ],
   "source": [
    "df_cpu.info()\n",
    "\n",
    "print(\"Examples of modified values in df_cpu in 'threads' column:\")\n",
    "if df_cpu_modified.empty:\n",
    "    print(\"No modifications were needed in 'threads' column.\")\n",
    "else:\n",
    "    print(df_cpu_modified.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fb2dfeac-b063-42c6-aa4f-8b610f8a9059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   image                  14 non-null     object\n",
      " 1   pid                    14 non-null     int64 \n",
      " 2   model                  14 non-null     object\n",
      " 3   read_byte_per_second   14 non-null     object\n",
      " 4   write_byte_per_second  14 non-null     object\n",
      " 5   delay                  14 non-null     int64 \n",
      " 6   total_byte_per_second  14 non-null     int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 916.0+ bytes\n",
      "Examples of modified values in df_disk in 'total_byte_per_second' column:\n",
      "                   image    pid model read_byte_per_second  \\\n",
      "0             chrome.exe   5448     x                    0   \n",
      "1             chrome.exe  13324    x3                    0   \n",
      "2              EXCEL.EXE  12132    x1               71,807   \n",
      "3  Grammarly.Desktop.exe  19180    h1                6,729   \n",
      "4     msedgewebview2.exe  20716    f1                1,365   \n",
      "\n",
      "  write_byte_per_second  delay total_byte_per_second  \n",
      "0                 6,278      0                 6,278  \n",
      "1                 4,940      0                 4,940  \n",
      "2                     0      0                71,807  \n",
      "3                     0      0                 6,729  \n",
      "4                 7,433      0                 8,799  \n"
     ]
    }
   ],
   "source": [
    "df_disk.info()\n",
    "\n",
    "print(\"Examples of modified values in df_disk in 'total_byte_per_second' column:\")\n",
    "print(df_disk_modified.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0643c610-ea2f-462e-ba41-bf0a16b20428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   image            306 non-null    object\n",
      " 1   pid              306 non-null    int64 \n",
      " 2   hard_faults/sec  306 non-null    int64 \n",
      " 3   commit_kb        306 non-null    object\n",
      " 4   working_set_kb   306 non-null    int64 \n",
      " 5   shareable_kb     306 non-null    object\n",
      " 6   private_kb       306 non-null    object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 16.9+ KB\n",
      "Examples of modified values in df_memory in 'working_set_kb' column:\n",
      "                           image    pid  hard_faults/sec commit_kb  \\\n",
      "0  AcrobatNotificationClient.exe  18096                0    40,272   \n",
      "1      Adobe Crash Processor.exe   7856                0     4,768   \n",
      "2      Adobe Desktop Service.exe   6640                0    85,284   \n",
      "3            AdobeCollabSync.exe  17928                0     7,016   \n",
      "4            AdobeCollabSync.exe  16808                0     4,148   \n",
      "\n",
      "  working_set_kb shareable_kb private_kb  \n",
      "0          3,632        3,392        240  \n",
      "1         15,252       13,704      1,548  \n",
      "2         85,504       75,696      9,808  \n",
      "3         20,384       17,980      2,404  \n",
      "4         16,628       15,700        928  \n"
     ]
    }
   ],
   "source": [
    "df_memory.info()\n",
    "print(\"Examples of modified values in df_memory in 'working_set_kb' column:\")\n",
    "print(df_memory_modified.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90df9d5d",
   "metadata": {},
   "source": [
    "### 4. Data Aggregation (30 pts):\n",
    "\n",
    "a. **Develop an `aggregate_data(dfx)` function that:**\n",
    "\n",
    "   - Accepts one of the dataframes (`df_cpu`, `df_disk`, or `df_memory`).\n",
    "   - Dynamically identifies the dataset based on its columns.\n",
    "   - Aggregates the data based on the specific dataset requirements provided below and returns an aggregated dataframe. You can name this new aggregated dataframe whatever name works (examples given).\n",
    "\n",
    "b. **Aggregation Requirements:**\n",
    "\n",
    "   i. For `df_cpu`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'threads' column. Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'threads_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_cpu_sum.\n",
    "   \n",
    "   ii. For `df_disk`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'total_byte_per_second' column.Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'total_byte_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_disk_sum.\n",
    "   \n",
    "   iii. For `df_memory`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'working_set_kb' column. Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'working_set_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_memory_sum.\n",
    "   \n",
    "   **Note: 'process_qty' is defined by grouping by 'image' and determining the number of times a particular image name occurs. Use the size() function for aggregation**\n",
    "          \n",
    "c. **Run `aggregate_data()` for each of your dataframes and save them into new dataframes. Print the head(10) and tail(10) for each of the new dataframes.**\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Function header:\n",
    "```python\n",
    "def aggregate_data(dfx):\n",
    "    # Your code aggregates the data based on the requirements provided.\n",
    "    return df_combo  # Name this resultant dataframe whatever name that works\n",
    "```\n",
    "Calling function and assigning the resultant dataframe to `df_cpu_sum`, `df_disk_sum`, `df_memory_sum`:\n",
    "```python\n",
    "df_cpu_sum = aggregate_data(df_cpu)\n",
    "df_disk_sum = aggregate_data(df_disk)\n",
    "df_memory_sum = aggregate_data(df_memory)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "32bafe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(dfx):\n",
    "    if 'threads' in dfx.columns:\n",
    "        # Aggregating df_cpu\n",
    "        df_combo = dfx.groupby('image', as_index=False).agg(\n",
    "            process_qty=('image', 'size'),\n",
    "            threads_sum=('threads', 'sum')\n",
    "        )\n",
    "    elif 'total_byte_per_second' in dfx.columns:\n",
    "        # Aggregating df_disk\n",
    "        df_combo = dfx.groupby('image', as_index=False).agg(\n",
    "            process_qty=('image', 'size'),\n",
    "            total_byte_sum=('total_byte_per_second', 'sum')\n",
    "        )\n",
    "    elif 'working_set_kb' in dfx.columns:\n",
    "        # Aggregating df_memory\n",
    "        df_combo = dfx.groupby('image', as_index=False).agg(\n",
    "            process_qty=('image', 'size'),\n",
    "            working_set_sum=('working_set_kb', 'sum')\n",
    "        )\n",
    "    return df_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a6bdd382-6058-453c-a951-d3b6b031b871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated df_cpu_sum:\n",
      "                           image  process_qty  threads_sum\n",
      "0  AcrobatNotificationClient.exe            1           13\n",
      "1      Adobe Crash Processor.exe            1            4\n",
      "2      Adobe Desktop Service.exe            1           47\n",
      "3            AdobeCollabSync.exe            2           24\n",
      "4             AdobeIPCBroker.exe            1           26\n",
      "5    AdobeNotificationClient.exe            1           12\n",
      "6         AdobeUpdateService.exe            1            5\n",
      "7             AggregatorHost.exe            1            1\n",
      "8       ApplicationFrameHost.exe            1            6\n",
      "9                  CCLibrary.exe            1            1\n",
      "                          image  process_qty  threads_sum\n",
      "140  svchost.exe (osprivacy -p)            1            4\n",
      "141       svchost.exe (smphost)            1            6\n",
      "142     svchost.exe (utcsvc -p)            1           12\n",
      "143               taskhostw.exe            1            8\n",
      "144                  uihost.exe            1           63\n",
      "145                unsecapp.exe            1            2\n",
      "146                vpnagent.exe            1            7\n",
      "147                 wininit.exe            1            2\n",
      "148                winlogon.exe            1            3\n",
      "149                 wlanext.exe            1            2\n"
     ]
    }
   ],
   "source": [
    "df_cpu_sum = aggregate_data(df_cpu)\n",
    "\n",
    "print(\"Aggregated df_cpu_sum:\")\n",
    "print(df_cpu_sum.head(10))\n",
    "print(df_cpu_sum.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4ee0187d-8897-4b4d-ba32-6e33fe041600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated df_disk_sum:\n",
      "                   image  process_qty  total_byte_sum\n",
      "0              EXCEL.EXE            1           71807\n",
      "1  Grammarly.Desktop.exe            1            6729\n",
      "2            MsMpEng.exe            1            1457\n",
      "3            OUTLOOK.EXE            1            1471\n",
      "4               Registry            1            5523\n",
      "5                 System            1          232627\n",
      "6              Teams.exe            1             547\n",
      "7           WUDFHost.exe            1           24587\n",
      "8             chrome.exe            2           11218\n",
      "9     msedgewebview2.exe            4           20060\n",
      "                   image  process_qty  total_byte_sum\n",
      "0              EXCEL.EXE            1           71807\n",
      "1  Grammarly.Desktop.exe            1            6729\n",
      "2            MsMpEng.exe            1            1457\n",
      "3            OUTLOOK.EXE            1            1471\n",
      "4               Registry            1            5523\n",
      "5                 System            1          232627\n",
      "6              Teams.exe            1             547\n",
      "7           WUDFHost.exe            1           24587\n",
      "8             chrome.exe            2           11218\n",
      "9     msedgewebview2.exe            4           20060\n"
     ]
    }
   ],
   "source": [
    "df_disk_sum = aggregate_data(df_disk)\n",
    "\n",
    "print(\"Aggregated df_disk_sum:\")\n",
    "print(df_disk_sum.head(10))\n",
    "print(df_disk_sum.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "72f02b52-0dd7-4c47-93fd-2e0097c5a5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated df_memory_sum:\n",
      "                           image  process_qty  working_set_sum\n",
      "0  AcrobatNotificationClient.exe            1             3632\n",
      "1      Adobe Crash Processor.exe            1            15252\n",
      "2      Adobe Desktop Service.exe            1            85504\n",
      "3            AdobeCollabSync.exe            2            37012\n",
      "4             AdobeIPCBroker.exe            1            10568\n",
      "5    AdobeNotificationClient.exe            1             2836\n",
      "6         AdobeUpdateService.exe            1             9580\n",
      "7             AggregatorHost.exe            1             7420\n",
      "8       ApplicationFrameHost.exe            1            35988\n",
      "9                  CCLibrary.exe            1             2948\n",
      "                          image  process_qty  working_set_sum\n",
      "141  svchost.exe (osprivacy -p)            1            13812\n",
      "142       svchost.exe (smphost)            1            16624\n",
      "143     svchost.exe (utcsvc -p)            1            30104\n",
      "144               taskhostw.exe            1            19400\n",
      "145                  uihost.exe            1            10472\n",
      "146                unsecapp.exe            1             7528\n",
      "147                vpnagent.exe            1            26192\n",
      "148                 wininit.exe            1             6264\n",
      "149                winlogon.exe            1            12320\n",
      "150                 wlanext.exe            1             6764\n"
     ]
    }
   ],
   "source": [
    "df_memory_sum = aggregate_data(df_memory)\n",
    "\n",
    "print(\"Aggregated df_memory_sum:\")\n",
    "print(df_memory_sum.head(10))\n",
    "print(df_memory_sum.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919d504b",
   "metadata": {},
   "source": [
    "### 5. Merging Data (10 pts):\n",
    "\n",
    "a. **Use the Pandas merge function to do an inner join on 'image_name' for dataframes `df_cpu_sum` and `df_disk_sum` created in the previous step. Store the result in a dataframe named `df_new`**.\n",
    "\n",
    "b. **Further merge `df_new` with `df_memory_sum` using an inner join on 'image_name'**.\n",
    "\n",
    "c. **Show the resulting dataframe in each of the steps above**\n",
    "\n",
    "Please refer to the pandas merge method and its parameters here : https://pandas.pydata.org/docs/reference/api/pandas.merge.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5ee2192e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge of df_cpu_sum and df_disk_sum:\n",
      "                   image  process_qty_x  threads_sum  process_qty_y  \\\n",
      "0              EXCEL.EXE              1           64              1   \n",
      "1  Grammarly.Desktop.exe              1           48              1   \n",
      "2            MsMpEng.exe              1           66              1   \n",
      "3            OUTLOOK.EXE              1           89              1   \n",
      "4               Registry              1            4              1   \n",
      "5                 System              1          342              1   \n",
      "6              Teams.exe              9          213              1   \n",
      "7           WUDFHost.exe              6           66              1   \n",
      "8             chrome.exe             12          236              2   \n",
      "9     msedgewebview2.exe             32          620              4   \n",
      "\n",
      "   total_byte_sum  \n",
      "0           71807  \n",
      "1            6729  \n",
      "2            1457  \n",
      "3            1471  \n",
      "4            5523  \n",
      "5          232627  \n",
      "6             547  \n",
      "7           24587  \n",
      "8           11218  \n",
      "9           20060  \n"
     ]
    }
   ],
   "source": [
    "df_new = pd.merge(df_cpu_sum, df_disk_sum, on='image', how='inner')\n",
    "\n",
    "print(\"Merge of df_cpu_sum and df_disk_sum:\")\n",
    "print(df_new.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "254e6d66-af7c-4959-9143-bcd234c8ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge with df_memory_sum:\n",
      "                   image  process_qty_x  threads_sum  process_qty_y  \\\n",
      "0              EXCEL.EXE              1           64              1   \n",
      "1  Grammarly.Desktop.exe              1           48              1   \n",
      "2            MsMpEng.exe              1           66              1   \n",
      "3            OUTLOOK.EXE              1           89              1   \n",
      "4               Registry              1            4              1   \n",
      "5                 System              1          342              1   \n",
      "6              Teams.exe              9          213              1   \n",
      "7           WUDFHost.exe              6           66              1   \n",
      "8             chrome.exe             12          236              2   \n",
      "9     msedgewebview2.exe             32          620              4   \n",
      "\n",
      "   total_byte_sum  process_qty  working_set_sum  \n",
      "0           71807            1           298380  \n",
      "1            6729            1           273436  \n",
      "2            1457            1           210204  \n",
      "3            1471            1           447040  \n",
      "4            5523            1            40864  \n",
      "5          232627            1             3140  \n",
      "6             547           10          1117452  \n",
      "7           24587            6            69316  \n",
      "8           11218           12          1076912  \n",
      "9           20060           32          1002516  \n"
     ]
    }
   ],
   "source": [
    "df_new = pd.merge(df_new, df_memory_sum, on='image', how='inner')\n",
    "\n",
    "print(\"Merge with df_memory_sum:\")\n",
    "print(df_new.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67a348",
   "metadata": {},
   "source": [
    "### 6. Filtering Data (30 pts):\n",
    "\n",
    "a. **Filter `df_new` to obtain:**\n",
    "\n",
    "   i. `image_name` that had 'working_set_sum' greater than 200,000. Store the result in a variable named 'high_memory_image'.\n",
    "\n",
    "   ii. `image_name` that had 'thread_sum' greater than 200. Store the result in a variable named 'high_thread_image'.\n",
    "\n",
    "   iii. `image_name` that had 'working_set_sum' greater than 200,000, 'thread_sum' less than 50, and 'total_byte_sum' less than 7,000. Store the result in a variable named 'hi_mem_low_thread_low_io'.\n",
    "   \n",
    "   iv. Show each of the filtered dataframe in separate cells. Feel free to add new cells to this notebook.  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "35dffad5-3660-4eca-9d52-b35dd2722848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high memory usage (working_set_sum > 200,000):\n",
      "                   image  process_qty_x  threads_sum  process_qty_y  \\\n",
      "0              EXCEL.EXE              1           64              1   \n",
      "1  Grammarly.Desktop.exe              1           48              1   \n",
      "2            MsMpEng.exe              1           66              1   \n",
      "3            OUTLOOK.EXE              1           89              1   \n",
      "6              Teams.exe              9          213              1   \n",
      "8             chrome.exe             12          236              2   \n",
      "9     msedgewebview2.exe             32          620              4   \n",
      "\n",
      "   total_byte_sum  process_qty  working_set_sum  \n",
      "0           71807            1           298380  \n",
      "1            6729            1           273436  \n",
      "2            1457            1           210204  \n",
      "3            1471            1           447040  \n",
      "6             547           10          1117452  \n",
      "8           11218           12          1076912  \n",
      "9           20060           32          1002516  \n"
     ]
    }
   ],
   "source": [
    "#filter images where 'working_set_sum' is greater than 200,000\n",
    "high_memory_image = df_new[df_new['working_set_sum'] > 200000]\n",
    "\n",
    "print(\"high memory usage (working_set_sum > 200,000):\")\n",
    "print(high_memory_image.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "17de6121-fa03-42d5-a3b3-aa7d3a1d2dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high thread count (threads_sum > 200):\n",
      "                image  process_qty_x  threads_sum  process_qty_y  \\\n",
      "5              System              1          342              1   \n",
      "6           Teams.exe              9          213              1   \n",
      "8          chrome.exe             12          236              2   \n",
      "9  msedgewebview2.exe             32          620              4   \n",
      "\n",
      "   total_byte_sum  process_qty  working_set_sum  \n",
      "5          232627            1             3140  \n",
      "6             547           10          1117452  \n",
      "8           11218           12          1076912  \n",
      "9           20060           32          1002516  \n"
     ]
    }
   ],
   "source": [
    "#filter images where 'threads_sum' is greater than 200\n",
    "high_thread_image = df_new[df_new['threads_sum'] > 200]\n",
    "\n",
    "print(\"high thread count (threads_sum > 200):\")\n",
    "print(high_thread_image.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1577a033-4047-4c1f-bc4e-9e3017109b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high memory, low thread, and low I/O:\n",
      "                   image  process_qty_x  threads_sum  process_qty_y  \\\n",
      "1  Grammarly.Desktop.exe              1           48              1   \n",
      "\n",
      "   total_byte_sum  process_qty  working_set_sum  \n",
      "1            6729            1           273436  \n"
     ]
    }
   ],
   "source": [
    "hi_mem_low_thread_low_io = df_new[\n",
    "    (df_new['working_set_sum'] > 200000) & \n",
    "    (df_new['threads_sum'] < 50) & \n",
    "    (df_new['total_byte_sum'] < 7000)\n",
    "]\n",
    "\n",
    "print(\"high memory, low thread, and low I/O:\")\n",
    "print(hi_mem_low_thread_low_io.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689a423-34ed-4a5f-be52-a52a4d579d35",
   "metadata": {},
   "source": [
    "### Coding Style (5 pts) \n",
    "Although we do not enforce a coding style such as PEP 8 (https://peps.python.org/pep-0008/) , please ensure that you have comments for each of the functions defined. Your code is readable, and includes only the code that is required by the assignment. Please remove any commented code, and experimental code that you may have tried. For each of the questions be sure to show some example rows of the dataframe that was modified or created.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b6af8-6b20-428a-b763-a4962c5de8bb",
   "metadata": {},
   "source": [
    "## Submission on Gradescope\n",
    "\n",
    "**Gradescope canvas left menu -> Gradescop -> PSET 5: Exploratory Data Analysis**\n",
    "\n",
    "**Submission :**\n",
    "Submit the jupyter notebook, and a pdf version of this notebook.\n",
    "\n",
    "To create a pdf of this notebook :  In your browser open print, and save as pdf. Name the pdf LastNameFirstName_pset5.pdf\n",
    "example: DoeJohn_pset5.pdf\n",
    "\n",
    "Name this jupyter notebook with the same format LastNameFirstName_pset5.ipynb\n",
    "\n",
    "Make sure that your notebook has been run before creating pdf. Any outputs from running the code needs to be clearly visible. We need both .ipynb, and pdf of this notebook to assign you grades. \n",
    "\n",
    "Drop all the files in gradescope under PSET 5: Exploratory Data Analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10836d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
