{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfdad8ff",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue;border: 2px solid gray;\">\n",
    "    <h2 style =\"text-align:center; padding-top:5px;\"> CS 101 - Foundation of Data Science and Engineering  </h2><br>\n",
    "    <p style=\"text-align:center;padding:5px; fontt-size:14px\"><b> PSET-5 - Exploratory Data Analysis (100 pts)<b></p> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aca83fb",
   "metadata": {},
   "source": [
    "# This is an individual assignment. No collaboration is allowed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7ec799",
   "metadata": {},
   "source": [
    "### Note: \n",
    "You are allowed to use all Python built-in functions and other Import features covered in class. Ensure your code is organized, well-commented, and follows the best practices we discussed. Remember, the key is not just to write a working program but to produce a solution that follows SPECS, is easy to debug, and is easy to maintain. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41163e5e",
   "metadata": {},
   "source": [
    "### Assignment Question List:\n",
    " \n",
    "**Question 1 : Data Extraction and cleaning (1 pts)**\n",
    "\n",
    "**Question 2 : Column Cleaning Function (15 pts)**\n",
    "\n",
    "**Question 3 : Data Cleaning (9 pts)**\n",
    "\n",
    "**Question 4 : Data Aggregation (30 pts)**\n",
    "\n",
    "**Question 5 : Merging Data (10 pts)**\n",
    "\n",
    "**Question 6 : Filtering Data (30 pts)**\n",
    "\n",
    "**Coding Style : (5 pts)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab336b0",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "**You are tasked with performing detailed exploratory data analysis on various system datasets: CPU, Disk, and Memory. Utilize Python functions to streamline data extraction, cleaning, and aggregation.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb32b9bd",
   "metadata": {},
   "source": [
    "### Datasets:\n",
    "\n",
    "1. **CPU Dataset: `cpu.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Description', 'Status', 'Threads', 'CPU', 'Average CPU'\n",
    "   <br><br>\n",
    "2. **Disk Dataset: `disk.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Model', 'Read Byte Per Second', 'Write Byte Per Second', 'Delay', 'Total Byte Per Second'\n",
    "    <br><br>\n",
    "3. **Memory Dataset: `memory.csv`**\n",
    "   - **Columns:** 'Image', 'PID', 'Hard Faults/sec', 'Commit KB', 'Working Set KB', 'Shareable KB', 'Private KB'\n",
    "    <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a89055f",
   "metadata": {},
   "source": [
    "# Your Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b1d8f8",
   "metadata": {},
   "source": [
    "### 1. Data Extraction (1 pts):\n",
    "\n",
    "a. **Load `cpu.csv` into a Pandas DataFrame named `df_cpu`. Extract only these columns:** 'Image', 'PID', 'Description', 'Status', 'Threads', 'Average CPU'\n",
    "\n",
    "b. **Load `disk.csv` into a DataFrame named `df_disk`. Extract only these columns:** 'Image', 'PID', 'Total Byte Per Second'\n",
    "\n",
    "c. **Load `memory.csv` into a DataFrame named `df_memory`. Extract only these columns:** 'Image', 'PID', 'Working Set KB'\n",
    "\n",
    "d. **For each of the above data frame show the shape, and info(example : df_cpu.info())**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2abb771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load datasets\n",
    "df_cpu = pd.read_csv(\"cpu.csv\")\n",
    "df_disk = pd.read_csv(\"disk.csv\")\n",
    "df_memory = pd.read_csv(\"memory.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b822932-5984-456c-a944-5ab01338cb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Image        306 non-null    object \n",
      " 1   PID          306 non-null    object \n",
      " 2   Description  290 non-null    object \n",
      " 3   Status       306 non-null    object \n",
      " 4   Threads      306 non-null    object \n",
      " 5   CPU          306 non-null    int64  \n",
      " 6   Average CPU  306 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 16.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((306, 7), None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cpu.shape, df_cpu.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa75e715-b3d1-4fdf-b8f9-d67d2eae2c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   Image                  14 non-null     object\n",
      " 1   PID                    14 non-null     int64 \n",
      " 2   Model                  14 non-null     object\n",
      " 3   Read Byte Per Second   14 non-null     object\n",
      " 4   Write Byte Per Second  14 non-null     object\n",
      " 5   Delay                  14 non-null     int64 \n",
      " 6   Total Byte Per Second  14 non-null     object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 916.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((14, 7), None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_disk.shape, df_disk.info(), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "020c0dee-133a-470e-a204-2ad5dd5b467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Image            306 non-null    object\n",
      " 1   PID              306 non-null    int64 \n",
      " 2   Hard Faults/sec  306 non-null    int64 \n",
      " 3   Commit KB        306 non-null    object\n",
      " 4   Working Set KB   306 non-null    object\n",
      " 5   Shareable KB     306 non-null    object\n",
      " 6   Private KB       306 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 16.9+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((306, 7), None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_memory.shape, df_memory.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dec275",
   "metadata": {},
   "source": [
    "### 2. Column Cleaning Function (15 pts):\n",
    "\n",
    "a. **Write a Python function, `CleanColumnHeading(dfx)`, to clean the column headers of any Pandas dataframe. The function should be dynamic enough to be able to process any datasets. The function should:**\n",
    "\n",
    "   i. Convert all column names to lowercase.\n",
    "   \n",
    "   ii. Replace spaces in column names with underscores `_`.\n",
    "\n",
    "   iii. Apply the `CleanColumnHeading` function to `df_cpu`, `df_disk`, and `df_memory`.\n",
    "\n",
    "   iv. Show examples of the changes.  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "Function header:\n",
    "```python\n",
    "def CleanColumnHeading(dfx):\n",
    "    # Your code to convert all column names to lowercase\n",
    "    # Your code to change all spaces in column names to underscores _\n",
    "    return dfx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f3b5beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanColumnHeading(dfx):\n",
    "    dfx.columns = dfx.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "    return dfx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0392dea-7102-4a1e-baf7-afa87d823ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpu = CleanColumnHeading(df_cpu)\n",
    "df_disk = CleanColumnHeading(df_disk)\n",
    "df_memory = CleanColumnHeading(df_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8db8ed38-5f06-4364-a146-825c01ea270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   image        306 non-null    object \n",
      " 1   pid          306 non-null    object \n",
      " 2   description  290 non-null    object \n",
      " 3   status       306 non-null    object \n",
      " 4   threads      306 non-null    object \n",
      " 5   cpu          306 non-null    int64  \n",
      " 6   average_cpu  306 non-null    float64\n",
      "dtypes: float64(1), int64(1), object(5)\n",
      "memory usage: 16.9+ KB\n",
      "            image    pid  description     status threads  cpu  average_cpu\n",
      "0   Secure System    140          NaN  Suspended       -    0          0.0\n",
      "1  SearchHost.exe   9272   SearchHost  Suspended      68    0          0.0\n",
      "2     LockApp.exe  12784  LockApp.exe  Suspended      16    0          0.0\n"
     ]
    }
   ],
   "source": [
    "df_cpu.info()\n",
    "print(df_cpu.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddd238f0-8152-4731-a8ba-503f5c59b21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   image                  14 non-null     object\n",
      " 1   pid                    14 non-null     int64 \n",
      " 2   model                  14 non-null     object\n",
      " 3   read_byte_per_second   14 non-null     object\n",
      " 4   write_byte_per_second  14 non-null     object\n",
      " 5   delay                  14 non-null     int64 \n",
      " 6   total_byte_per_second  14 non-null     object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 916.0+ bytes\n",
      "        image    pid model read_byte_per_second write_byte_per_second  delay  \\\n",
      "0  chrome.exe   5448     x                    0                 6,278      0   \n",
      "1  chrome.exe  13324    x3                    0                 4,940      0   \n",
      "2   EXCEL.EXE  12132    x1               71,807                     0      0   \n",
      "\n",
      "  total_byte_per_second  \n",
      "0                 6,278  \n",
      "1                 4,940  \n",
      "2                71,807  \n"
     ]
    }
   ],
   "source": [
    "df_disk.info()\n",
    "print(df_disk.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8abdc19b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   image            306 non-null    object\n",
      " 1   pid              306 non-null    int64 \n",
      " 2   hard_faults/sec  306 non-null    int64 \n",
      " 3   commit_kb        306 non-null    object\n",
      " 4   working_set_kb   306 non-null    object\n",
      " 5   shareable_kb     306 non-null    object\n",
      " 6   private_kb       306 non-null    object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 16.9+ KB\n",
      "                           image    pid  hard_faults/sec commit_kb  \\\n",
      "0  AcrobatNotificationClient.exe  18096                0    40,272   \n",
      "1      Adobe Crash Processor.exe   7856                0     4,768   \n",
      "2      Adobe Desktop Service.exe   6640                0    85,284   \n",
      "\n",
      "  working_set_kb shareable_kb private_kb  \n",
      "0          3,632        3,392        240  \n",
      "1         15,252       13,704      1,548  \n",
      "2         85,504       75,696      9,808  \n"
     ]
    }
   ],
   "source": [
    "df_memory.info()\n",
    "print(df_memory.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e86fa-c8c8-4e50-9f75-517491d29e68",
   "metadata": {},
   "source": [
    "### 3. Data cleaning (9 pts)\n",
    "**Examine the columns 'threads', 'total_byte_per_second', 'working_set_kb' from the dataframes df_cpu, df_disk, and df_memory. We are going to work with these columns Question 4-6. Ensure that they have the correct data type, fix the values if required so. If there are invalid values drop them. At the end of this step you should not have any invalid values, and the correct data type set for the 3 columns. You are not required to do data cleaning on other columns. If you choose to do so, please ensure that no rows are dropped while cleaning these columns** \n",
    "\n",
    "**Hint: values such as 71,807 are not invalid. They are simply string representation of the number 71807. Fix it so they are stored as 71807, and the column datatype should either be a float or int.** \n",
    "\n",
    "\n",
    "**For each of the columns modified , show example rows of what was modified. Also call the info() method on each of the dataframes.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61a1a8e5-9532-4624-a143-2ff579b99909",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_column(dfx, column_name):\n",
    "    dfx[column_name] = pd.to_numeric(dfx[column_name].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "    #drop rows with NaN\n",
    "    dfx.dropna(subset=[column_name], inplace=True)\n",
    "    #convert to integer type if possible\n",
    "    if dfx[column_name].dtype == 'float64' and (dfx[column_name] % 1 == 0).all():\n",
    "        dfx[column_name] = dfx[column_name].astype(int)\n",
    "\n",
    "    return dfx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c7d2c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_cpu columns: Index(['image', 'pid', 'description', 'status', 'threads', 'cpu',\n",
      "       'average_cpu'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"df_cpu columns:\", df_cpu.columns)\n",
    "#print(\"df_cpu_cleaned columns:\", df_cpu_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "50664004-97f4-4f5e-b47b-b4c1d75cc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cpu_cleaned = df_cpu.copy()\n",
    "df_disk_cleaned = df_disk.copy()\n",
    "df_memory_cleaned = df_memory.copy()\n",
    "df_cpu_cleaned = clean_numeric_column(df_cpu_cleaned, 'threads')\n",
    "df_disk_cleaned = clean_numeric_column(df_disk_cleaned, 'total_byte_per_second')\n",
    "df_memory_cleaned = clean_numeric_column(df_memory_cleaned, 'working_set_kb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8418df3f-bd4c-4179-ae8b-3b705164902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 304 entries, 1 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   image        304 non-null    object \n",
      " 1   pid          304 non-null    object \n",
      " 2   description  289 non-null    object \n",
      " 3   status       304 non-null    object \n",
      " 4   threads      304 non-null    int64  \n",
      " 5   cpu          304 non-null    int64  \n",
      " 6   average_cpu  304 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 19.0+ KB\n",
      "                           image    pid                description     status  \\\n",
      "1                 SearchHost.exe   9272                 SearchHost  Suspended   \n",
      "2                    LockApp.exe  12784                LockApp.exe  Suspended   \n",
      "3  AcrobatNotificationClient.exe  18096  AcrobatNotificationClient  Suspended   \n",
      "\n",
      "   threads  cpu  average_cpu  \n",
      "1       68    0          0.0  \n",
      "2       16    0          0.0  \n",
      "3       13    0          0.0  \n"
     ]
    }
   ],
   "source": [
    "df_cpu_cleaned.info()\n",
    "print(df_cpu_cleaned.head(3))\n",
    "column_to_check = 'threads'\n",
    "df_cpu_comparison = df_cpu.merge(df_cpu_cleaned, on=\"pid\", suffixes=(\"_before\", \"_after\"))\n",
    "differences = df_cpu_comparison[df_cpu_comparison[f\"{column_to_check}_before\"] != df_cpu_comparison[f\"{column_to_check}_after\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce3c0c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    threads_before  threads_after\n",
      "0               68             68\n",
      "1               16             16\n",
      "2               13             13\n",
      "3               12             12\n",
      "4               18             18\n",
      "..             ...            ...\n",
      "299              7              7\n",
      "300              3              3\n",
      "301             13             13\n",
      "302              6              6\n",
      "303             17             17\n",
      "\n",
      "[304 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(differences[[f\"{column_to_check}_before\", f\"{column_to_check}_after\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6e988c47-5362-4b97-8ae3-eb77936239c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 306 entries, 0 to 305\n",
      "Data columns (total 7 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   image            306 non-null    object\n",
      " 1   pid              306 non-null    int64 \n",
      " 2   hard_faults/sec  306 non-null    int64 \n",
      " 3   commit_kb        306 non-null    object\n",
      " 4   working_set_kb   306 non-null    int64 \n",
      " 5   shareable_kb     306 non-null    object\n",
      " 6   private_kb       306 non-null    object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 16.9+ KB\n",
      "                           image    pid  hard_faults/sec commit_kb  \\\n",
      "0  AcrobatNotificationClient.exe  18096                0    40,272   \n",
      "1      Adobe Crash Processor.exe   7856                0     4,768   \n",
      "2      Adobe Desktop Service.exe   6640                0    85,284   \n",
      "\n",
      "   working_set_kb shareable_kb private_kb  \n",
      "0            3632        3,392        240  \n",
      "1           15252       13,704      1,548  \n",
      "2           85504       75,696      9,808  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'total_byte_per_second_before'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'total_byte_per_second_before'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m column_to_check \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_byte_per_second\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m df_memory_comparison \u001b[38;5;241m=\u001b[39m df_memory\u001b[38;5;241m.\u001b[39mmerge(df_memory_cleaned, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m\"\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_before\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_after\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m differences \u001b[38;5;241m=\u001b[39m df_memory_comparison[df_memory_comparison[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_before\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m df_memory_comparison[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_to_check\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_after\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'total_byte_per_second_before'"
     ]
    }
   ],
   "source": [
    "df_memory_cleaned.info()\n",
    "print(df_memory_cleaned.head(3))\n",
    "column_to_check = 'total_byte_per_second'\n",
    "df_memory_comparison = df_memory.merge(df_memory_cleaned, on=\"pid\", suffixes=(\"_before\", \"_after\"))\n",
    "differences = df_memory_comparison[df_memory_comparison[f\"{column_to_check}_before\"] != df_memory_comparison[f\"{column_to_check}_after\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb2dfeac-b063-42c6-aa4f-8b610f8a9059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14 entries, 0 to 13\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   image                  14 non-null     object\n",
      " 1   pid                    14 non-null     int64 \n",
      " 2   model                  14 non-null     object\n",
      " 3   read_byte_per_second   14 non-null     object\n",
      " 4   write_byte_per_second  14 non-null     object\n",
      " 5   delay                  14 non-null     int64 \n",
      " 6   total_byte_per_second  14 non-null     int64 \n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 916.0+ bytes\n",
      "        image    pid model read_byte_per_second write_byte_per_second  delay  \\\n",
      "0  chrome.exe   5448     x                    0                 6,278      0   \n",
      "1  chrome.exe  13324    x3                    0                 4,940      0   \n",
      "2   EXCEL.EXE  12132    x1               71,807                     0      0   \n",
      "\n",
      "   total_byte_per_second  \n",
      "0                   6278  \n",
      "1                   4940  \n",
      "2                  71807  \n"
     ]
    }
   ],
   "source": [
    "df_disk_cleaned.info()\n",
    "print(df_disk_cleaned.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643c610-ea2f-462e-ba41-bf0a16b20428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90df9d5d",
   "metadata": {},
   "source": [
    "### 4. Data Aggregation (30 pts):\n",
    "\n",
    "a. **Develop an `aggregate_data(dfx)` function that:**\n",
    "\n",
    "   - Accepts one of the dataframes (`df_cpu`, `df_disk`, or `df_memory`).\n",
    "   - Dynamically identifies the dataset based on its columns.\n",
    "   - Aggregates the data based on the specific dataset requirements provided below and returns an aggregated dataframe. You can name this new aggregated dataframe whatever name works (examples given).\n",
    "\n",
    "b. **Aggregation Requirements:**\n",
    "\n",
    "   i. For `df_cpu`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'threads' column. Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'threads_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_cpu_sum.\n",
    "   \n",
    "   ii. For `df_disk`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'total_byte_per_second' column.Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'total_byte_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_disk_sum.\n",
    "   \n",
    "   iii. For `df_memory`:\n",
    "   \n",
    "          1. Group by 'image' and aggregate the 'working_set_kb' column. Use the sum() function for aggregation.\n",
    "          2. The resultant dataframe should contain: 'image_name', 'process_qty', 'working_set_sum'.\n",
    "          3. Reset the index after aggregation.\n",
    "          4. Assign the new aggregated dataframe values to df_memory_sum.\n",
    "   \n",
    "   **Note: 'process_qty' is defined by grouping by 'image' and determining the number of times a particular image name occurs. Use the size() function for aggregation**\n",
    "          \n",
    "c. **Run `aggregate_data()` for each of your dataframes and save them into new dataframes. Print the head(10) and tail(10) for each of the new dataframes.**\n",
    "\n",
    "**Example:**\n",
    "\n",
    "Function header:\n",
    "```python\n",
    "def aggregate_data(dfx):\n",
    "    # Your code aggregates the data based on the requirements provided.\n",
    "    return df_combo  # Name this resultant dataframe whatever name that works\n",
    "```\n",
    "Calling function and assigning the resultant dataframe to `df_cpu_sum`, `df_disk_sum`, `df_memory_sum`:\n",
    "```python\n",
    "df_cpu_sum = aggregate_data(df_cpu)\n",
    "df_disk_sum = aggregate_data(df_disk)\n",
    "df_memory_sum = aggregate_data(df_memory)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32bafe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bdd382-6058-453c-a951-d3b6b031b871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0187d-8897-4b4d-ba32-6e33fe041600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f02b52-0dd7-4c47-93fd-2e0097c5a5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ddf03-9bd5-4635-a2ed-c4235bb31500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302de26-0c2f-41db-ab72-1dddb44d0162",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9700e5e-c3f2-4f40-8fc5-eda9032517fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "919d504b",
   "metadata": {},
   "source": [
    "### 5. Merging Data (10 pts):\n",
    "\n",
    "a. **Use the Pandas merge function to do an inner join on 'image_name' for dataframes `df_cpu_sum` and `df_disk_sum` created in the previous step. Store the result in a dataframe named `df_new`**.\n",
    "\n",
    "b. **Further merge `df_new` with `df_memory_sum` using an inner join on 'image_name'**.\n",
    "\n",
    "c. **Show the resulting dataframe in each of the steps above**\n",
    "\n",
    "Please refer to the pandas merge method and its parameters here : https://pandas.pydata.org/docs/reference/api/pandas.merge.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee2192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e6d66-af7c-4959-9143-bcd234c8ab2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322167a-c525-41e0-a4f1-1bcef7b39d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e67a348",
   "metadata": {},
   "source": [
    "### 6. Filtering Data (30 pts):\n",
    "\n",
    "a. **Filter `df_new` to obtain:**\n",
    "\n",
    "   i. `image_name` that had 'working_set_sum' greater than 200,000. Store the result in a variable named 'high_memory_image'.\n",
    "\n",
    "   ii. `image_name` that had 'thread_sum' greater than 200. Store the result in a variable named 'high_thread_image'.\n",
    "\n",
    "   iii. `image_name` that had 'working_set_sum' greater than 200,000, 'thread_sum' less than 50, and 'total_byte_sum' less than 7,000. Store the result in a variable named 'hi_mem_low_thread_low_io'.\n",
    "   \n",
    "   iv. Show each of the filtered dataframe in separate cells. Feel free to add new cells to this notebook.  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35dffad5-3660-4eca-9d52-b35dd2722848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your  code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17de6121-fa03-42d5-a3b3-aa7d3a1d2dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1577a033-4047-4c1f-bc4e-9e3017109b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48f08e3-1fd7-4baa-8391-8f94b5d916bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8e545-0115-44c6-8eb9-71a814fc2900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea7cfcc-bc48-4fd6-a027-c46e3fede9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4689a423-34ed-4a5f-be52-a52a4d579d35",
   "metadata": {},
   "source": [
    "### Coding Style (5 pts) \n",
    "Although we do not enforce a coding style such as PEP 8 (https://peps.python.org/pep-0008/) , please ensure that you have comments for each of the functions defined. Your code is readable, and includes only the code that is required by the assignment. Please remove any commented code, and experimental code that you may have tried. For each of the questions be sure to show some example rows of the dataframe that was modified or created.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300b6af8-6b20-428a-b763-a4962c5de8bb",
   "metadata": {},
   "source": [
    "## Submission on Gradescope\n",
    "\n",
    "**Gradescope canvas left menu -> Gradescop -> PSET 5: Exploratory Data Analysis**\n",
    "\n",
    "**Submission :**\n",
    "Submit the jupyter notebook, and a pdf version of this notebook.\n",
    "\n",
    "To create a pdf of this notebook :  In your browser open print, and save as pdf. Name the pdf LastNameFirstName_pset5.pdf\n",
    "example: DoeJohn_pset5.pdf\n",
    "\n",
    "Name this jupyter notebook with the same format LastNameFirstName_pset5.ipynb\n",
    "\n",
    "Make sure that your notebook has been run before creating pdf. Any outputs from running the code needs to be clearly visible. We need both .ipynb, and pdf of this notebook to assign you grades. \n",
    "\n",
    "Drop all the files in gradescope under PSET 5: Exploratory Data Analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10836d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
